{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "VPs-e4DqEWW5"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Flatten,Dense\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plot\n",
        "from glob import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt1dVBjlfG9B",
        "outputId": "cfa6e303-0978-4487-f136-a403d2430b6d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYlGOHCmfTSQ",
        "outputId": "0c3f9e1e-c140-4228-f801-ad0edb14cb65"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install glob2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcGmh5pQfW5D",
        "outputId": "5274c7e2-6a56-4779-eb1f-e0db49845351"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGESHAPE = [224, 224, 3]\n",
        "training_data = 'chest_xray/train'\n",
        "testing_data = 'chest_xray/test'\n"
      ],
      "metadata": {
        "id": "7V0_EEe4ErVY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vZ-_2N_fOn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "id": "GPwGJfYFExrR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /root/.keras/models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA3izqvmEyKX",
        "outputId": "6a1f9767-7541-4dae-b707-6670514e06fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 57M\n",
            "-rw-r--r-- 1 root root 57M May 29 15:58 vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each_layer in vgg_model.layers:\n",
        "\teach_layer.trainable = False\n"
      ],
      "metadata": {
        "id": "x0DnxIrgHaRB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = glob('chest_xray/train/*')\n"
      ],
      "metadata": {
        "id": "ikseuIMRHio5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = Flatten()(vgg_model.output)\n",
        "prediction = Dense(len(classes), activation='softmax')(flatten_layer)\n"
      ],
      "metadata": {
        "id": "I25Y6I3iHnPR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/chest_xray/train'  # Ensure this is the correct path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzfqDySthyoE",
        "outputId": "b80faa5d-13d9-428a-b70e-8dfcf5658b81"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Path to your dataset\n",
        "data_path = '/content/drive/MyDrive/chest_xray/train'  # Replace with your actual dataset path\n",
        "data_p ='/content/drive/MyDrive/chest_xray/val'\n",
        "# Parameters\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "validation_split = 0.2\n",
        "seed = 123\n",
        "image_size = (img_height, img_width)\n",
        "\n",
        "# Load the training dataset\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split=validation_split,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load the validation dataset\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    data_p,\n",
        "    validation_split=validation_split,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "# Normalization layer\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "# Apply the transformations to the training dataset\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Apply normalization to the validation dataset\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Optimize dataset loading\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Define the model\n",
        "num_classes = 2  # Replace 2 with the actual number of classes in your dataset\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_dataset)\n",
        "print(f\"Validation accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9XcjXbngIw5",
        "outputId": "80592749-6346-4a16-cbf3-aa60e40194d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5211 files belonging to 2 classes.\n",
            "Using 4169 files for training.\n",
            "Found 16 files belonging to 2 classes.\n",
            "Using 3 files for validation.\n",
            "Epoch 1/10\n",
            "131/131 [==============================] - 848s 4s/step - loss: 0.5577 - accuracy: 0.7292 - val_loss: 0.3245 - val_accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 486s 4s/step - loss: 0.4155 - accuracy: 0.7836 - val_loss: 0.5116 - val_accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 493s 4s/step - loss: 0.3244 - accuracy: 0.8429 - val_loss: 0.2955 - val_accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 487s 4s/step - loss: 0.2583 - accuracy: 0.8952 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "131/131 [==============================] - 487s 4s/step - loss: 0.2331 - accuracy: 0.9084 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "131/131 [==============================] - 482s 4s/step - loss: 0.1962 - accuracy: 0.9247 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "131/131 [==============================] - 489s 4s/step - loss: 0.1595 - accuracy: 0.9348 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            " 22/131 [====>.........................] - ETA: 6:49 - loss: 0.1569 - accuracy: 0.9304"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = Model(inputs=vgg_model.input, outputs=prediction)\n",
        "final_model.summary()\n"
      ],
      "metadata": {
        "id": "EFuKAmbpHqzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.compile(\n",
        "loss='categorical_crossentropy',\n",
        "optimizer='adam',\n",
        "metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "jC4tcYnVIGS4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "\t\t\t\t\t\t\t\tshear_range = 0.2,\n",
        "\t\t\t\t\t\t\t\tzoom_range = 0.2,\n",
        "\t\t\t\t\t\t\t\thorizontal_flip = True)\n",
        "testing_datagen = ImageDataGenerator(rescale =1. / 255)\n"
      ],
      "metadata": {
        "id": "TRcIl-2EIJDa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('chest_xray/train',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = 4,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "KjgbP5QUHuBS",
        "outputId": "81dcff87-cfc0-477e-eded-fc9303cd5162"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'chest_xray/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-011257968903>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_set = train_datagen.flow_from_directory('chest_xray/train', \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                                                 \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                                                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical') \n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \"\"\"\n\u001b[0;32m-> 1649\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1650\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chest_xray/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = testing_datagen.flow_from_directory('chest_xray/test',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\tbatch_size = 4,\n",
        "\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n"
      ],
      "metadata": {
        "id": "kTHapvFCIT3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_model = final_model.fit_generator(\n",
        "training_set,\n",
        "validation_data=test_set,\n",
        "epochs=5,\n",
        "steps_per_epoch=len(training_set),\n",
        "validation_steps=len(test_set)\n",
        ")\n"
      ],
      "metadata": {
        "id": "708FMA3VJROC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.save('our_model.h5')\n"
      ],
      "metadata": {
        "id": "OUBufl-AJXGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing import image\n",
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "model=load_model('our_model.h5') #Loading our model\n",
        "img=image.load_img('D:/Semester - 6/PneumoniaGFG/chest_xray/val/PNEUMONIA/person1954_bacteria_4886.jpeg',target_size=(224,224))\n",
        "imagee=image.img_to_array(img) #Converting the X-Ray into pixels\n",
        "imagee=np.expand_dims(imagee, axis=0)\n",
        "img_data=preprocess_input(imagee)\n",
        "prediction=model.predict(img_data)\n",
        "if prediction[0][0]>prediction[0][1]: #Printing the prediction of model.\n",
        "\tprint('Person is safe.')\n",
        "else:\n",
        "\tprint('Person is affected with Pneumonia.')\n",
        "print(f'Predictions: {prediction}')\n"
      ],
      "metadata": {
        "id": "vs75qR3mJbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Flatten,Dense\n",
        "from keras.applications.vgg16 import VGG16 #Import all the necessary modules\n",
        "import matplotlib.pyplot as plot\n",
        "from glob import glob\n",
        "\n",
        "IMAGESHAPE = [224, 224, 3] #Provide image size as 224 x 224 this is a fixed-size for VGG16 architecture\n",
        "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)\n",
        "#3 signifies that we are working with RGB type of images.\n",
        "training_data = 'chest_xray/train'\n",
        "testing_data = 'chest_xray/test' #Give our training and testing path\n",
        "\n",
        "for each_layer in vgg_model.layers:\n",
        "\teach_layer.trainable = False #Set the trainable as False, So that all the layers would not be trained.\n",
        "classes = glob('chest_xray/train/*') #Finding how many classes present in our train dataset.\n",
        "flatten_layer = Flatten()(vgg_model.output)\n",
        "prediction = Dense(len(classes), activation='softmax')(flatten_layer)\n",
        "final_model = Model(inputs=vgg_model.input, outputs=prediction) #Combine the VGG output and prediction , this all together will create a model.\n",
        "final_model.summary() #Displaying the summary\n",
        "final_model.compile( #Compiling our model using adam optimizer and optimization metric as accuracy.\n",
        "loss='categorical_crossentropy',\n",
        "optimizer='adam',\n",
        "metrics=['accuracy']\n",
        ")\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, #importing our dataset to keras using ImageDataGenerator in keras.\n",
        "\t\t\t\t\t\t\t\tshear_range = 0.2,\n",
        "\t\t\t\t\t\t\t\tzoom_range = 0.2,\n",
        "\t\t\t\t\t\t\t\thorizontal_flip = True)\n",
        "testing_datagen = ImageDataGenerator(rescale =1. / 255)\n",
        "training_set = train_datagen.flow_from_directory('chest_xray/train', #inserting the images.\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = 4,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n",
        "test_set = testing_datagen.flow_from_directory('chest_xray/test',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\tbatch_size = 4,\n",
        "\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n",
        "fitted_model = final_model.fit_generator( #Fitting the model.\n",
        "training_set,\n",
        "validation_data=test_set,\n",
        "epochs=5,\n",
        "steps_per_epoch=len(training_set),\n",
        "validation_steps=len(test_set)\n",
        ")\n",
        "plot.plot(fitted_model.history['loss'], label='training loss') #Plotting the accuracies\n",
        "plot.plot(fitted_model.history['val_loss'], label='validation loss')\n",
        "plot.legend()\n",
        "plot.show()\n",
        "plot.savefig('LossVal_loss')\n",
        "plot.plot(fitted_model.history['acc'], label='training accuracy')\n",
        "plot.plot(fitted_model.history['val_acc'], label='validation accuracy')\n",
        "plot.legend()\n",
        "plot.show()\n",
        "plot.savefig('AccVal_acc')\n",
        "final_model.save('our_model.h5') #Saving the model file.\n"
      ],
      "metadata": {
        "id": "lASsKkaCJeJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Model\n",
        "from keras_preprocessing import image\n",
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "model=load_model('our_model.h5') #Loading our model\n",
        "img=image.load_img('D:/Semester - 6/PneumoniaGFG/chest_xray/val/PNEUMONIA/person1954_bacteria_4886.jpeg',target_size=(224,224))\n",
        "imagee=image.img_to_array(img) #Converting the X-Ray into pixels\n",
        "imagee=np.expand_dims(imagee, axis=0)\n",
        "img_data=preprocess_input(imagee)\n",
        "prediction=model.predict(img_data)\n",
        "if prediction[0][0]>prediction[0][1]: #Printing the prediction of model.\n",
        "\tprint('Person is safe.')\n",
        "else:\n",
        "\tprint('Person is affected with Pneumonia.')\n",
        "print(f'Predictions: {prediction}')\n"
      ],
      "metadata": {
        "id": "Hz4V8znLJi-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}